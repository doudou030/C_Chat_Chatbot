{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirement\n",
        "numpy==1.23.4\n",
        "\n",
        "pandas==1.5.3\n",
        "\n",
        "tensorflow==2.10.1\n",
        "\n",
        "tqdm==4.65.0"
      ],
      "metadata": {
        "id": "mftkI0zPgMTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import library & parameters\n"
      ],
      "metadata": {
        "id": "1OxhMDYz0aVy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVuNvVDbgNyG"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "### Control tensorflow won't occupied all your GPU memory\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "### Configs --> Parameters you can attempt to tuning\n",
        "MAXLEN = 128 # If you data has short sentence, please try lower MAXLEN in order to increase performance of model training\n",
        "EPOCHS = 10000\n",
        "BATCH_SIZE = 64\n",
        "EMB_DIM = 100\n",
        "UNIT = 128"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lLCGfzUKF4f"
      },
      "source": [
        "# load Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/doudou030/C_Chat_Chatbot.git\n",
        "!cp C_Chat_Chatbot/train_data/train.txt train.txt\n",
        "!cp C_Chat_Chatbot/train_data/train.json train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQA4WATUztA4",
        "outputId": "0c78287e-7a82-4adf-bd8a-182ad2a47f74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'C_Chat_Chatbot'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 26 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), 6.21 MiB | 5.23 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_data = []\n",
        "a_data = []\n",
        "f = open('/content/train.txt')\n",
        "lines = f.readlines() #總共行數\n",
        "for line in lines:\n",
        "    line = line.strip()  \n",
        "    if line.startswith('Q:'):\n",
        "        q_data.append(line[3:])  \n",
        "    elif line.startswith('A:'):\n",
        "        a_data.append(line[3:])  \n",
        "f.close\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT7H5nXJzrg_",
        "outputId": "8e2ba679-7fab-4ba8-ee43-46722bc921e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close()>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVJIEKq0uBW"
      },
      "source": [
        "q_data = np.array(q_data)\n",
        "a_data = np.array(a_data)\n",
        "q_data, a_data = shuffle(q_data,a_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XEsjnLrjTed"
      },
      "source": [
        "q, a = [], []\n",
        "for i in range(len(q_data)):\n",
        "  seq_q, seq_a = q_data[i][0], a_data[i][0]\n",
        "  q.append(\"\".join(seq_q))\n",
        "  a.append(\"\".join(seq_a))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWp4HpRTkTyZ"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijlnqTrDkTVT"
      },
      "source": [
        "### Build character-based vocabulary\n",
        "def tokenize_chinese(texts, voc, voc_ind):\n",
        "    for t in tqdm(texts):\n",
        "        for ch in str(t):\n",
        "            if ch not in voc:\n",
        "                voc[ch] = voc_ind\n",
        "                voc_ind += 1 \n",
        "    return voc, voc_ind"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc = {} # Vocabulary dictionary\n",
        "voc_ind = 1 # vocabulary index start from 1, index 0 means nothing\n",
        "\n",
        "voc, voc_ind = tokenize_chinese(q, voc, voc_ind)\n",
        "voc, voc_ind = tokenize_chinese(a, voc, voc_ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TL8aadezMMC",
        "outputId": "82e49608-5c20-4622-c374-14ef86ba8b26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49478/49478 [00:00<00:00, 3242488.88it/s]\n",
            "100%|██████████| 49478/49478 [00:00<00:00, 2159881.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data preprocessing"
      ],
      "metadata": {
        "id": "Daa4CTL82eWI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gNdd144kosm"
      },
      "source": [
        "def fit_sentence(sen, voc):\n",
        "    res = []\n",
        "    for i in sen:\n",
        "        res.append(voc[i])\n",
        "    return res"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5di4_qskXru"
      },
      "source": [
        "### Insert \"Start Of Sentence\" token into vocabulary\n",
        "voc[\"<SOS>\"] = len(voc)+1\n",
        "### Insert \"End Of Sentence\" token into vocabulary\n",
        "voc[\"<EOS>\"] = len(voc)+1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_x = []\n",
        "ans_x, ans_y = [], []"
      ],
      "metadata": {
        "id": "LSfPi2jF0iEL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Question input\n",
        "for i in tqdm(q):\n",
        "    res = fit_sentence(i, voc)\n",
        "    while len(res) < MAXLEN: ### If sentence is shorter than maxlen, append 0 until length reach maxlen\n",
        "        res.append(0)\n",
        "    q_x.append(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKWEkvAc0jF6",
        "outputId": "3025c183-9c54-4f08-8c6e-f0cf381941c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49478/49478 [00:01<00:00, 43921.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Answer input\n",
        "for i in tqdm(a):\n",
        "    res = fit_sentence(i, voc)\n",
        "    res.insert(0,voc[\"<SOS>\"])\n",
        "    res.append(voc[\"<EOS>\"])\n",
        "    while len(res) < MAXLEN: ### If sentence is shorter than maxlen, append 0 until length reach maxlen\n",
        "        res.append(0)\n",
        "    ans_x.append(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I39Qkl-q0pja",
        "outputId": "d1edf0f6-a777-4ed6-d6fe-df52578254c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49478/49478 [00:01<00:00, 37537.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Answer output\n",
        "for i in ans_x:\n",
        "    tmp = i[1:]\n",
        "    tmp.append(0)\n",
        "    ans_y.append(tmp)"
      ],
      "metadata": {
        "id": "V6L5I8gw0uc1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Turn into np.array for training\n",
        "q_x = np.array(q_x)\n",
        "ans_x = np.array(ans_x)\n",
        "ans_y = np.array(ans_y)"
      ],
      "metadata": {
        "id": "p21tK9s50xsT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Er55MSAl5T"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJkAeP-eoF6f"
      },
      "source": [
        "def build_model(voc):\n",
        "    Q_in = Input((MAXLEN,),name='Q_input')\n",
        "    Q_emb = Embedding(len(voc)+1,EMB_DIM,mask_zero=True,name='Q_emb')(Q_in)\n",
        "    Q_out, Q_h, Q_c = LSTM(UNIT,return_state=True,recurrent_dropout=0.2,name='Q_LSTM')(Q_emb)\n",
        "    Q_state = [Q_h,Q_c]\n",
        "    A_in = Input((MAXLEN,),name='A_input')\n",
        "    A_emb = Embedding(len(voc)+1,EMB_DIM,mask_zero=True,name='A_emb')(A_in)\n",
        "    A_out = LSTM(UNIT,return_sequences=True,recurrent_dropout=0.2,name='A_LSTM')(A_emb,initial_state=Q_state)\n",
        "    output = Dense(len(voc)+1,activation='softmax',name='Output')(A_out)\n",
        "\n",
        "    model = Model(inputs=[Q_in,A_in],outputs=output,name='Gossip_ChatBot')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ6HCEd7xKi1",
        "outputId": "cb6b56d0-ddee-4c69-fe47-cb1c2ce42419"
      },
      "source": [
        "model = build_model(voc)\n",
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Gossip_ChatBot\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Q_input (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " A_input (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " Q_emb (Embedding)              (None, 128, 100)     251100      ['Q_input[0][0]']                \n",
            "                                                                                                  \n",
            " A_emb (Embedding)              (None, 128, 100)     251100      ['A_input[0][0]']                \n",
            "                                                                                                  \n",
            " Q_LSTM (LSTM)                  [(None, 128),        117248      ['Q_emb[0][0]']                  \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " A_LSTM (LSTM)                  (None, 128, 128)     117248      ['A_emb[0][0]',                  \n",
            "                                                                  'Q_LSTM[0][1]',                 \n",
            "                                                                  'Q_LSTM[0][2]']                 \n",
            "                                                                                                  \n",
            " Output (Dense)                 (None, 128, 2511)    323919      ['A_LSTM[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,060,615\n",
            "Trainable params: 1,060,615\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Callbacks --> Checkpoint: Change file path to the directory where you want to save your model\n",
        "checkpoint = ModelCheckpoint(filepath=\"./models/chatbot_LSTM.h5\", monitor='accuracy',verbose=1,save_best_only=True,save_weights_only=True)\n",
        "### Callbacks --> Earlystop: Monitor accuracy and decide whether to stop the training procedure\n",
        "earlystop = EarlyStopping(monitor='accuracy',patience=3,verbose=1)\n",
        "\n",
        "### If you have model trained before, you can load it back and continue previous training procedure\n",
        "try:\n",
        "    model.load_weights('chatbot.h5')\n",
        "    print(\"Load model...\")\n",
        "### If you haven't train any model yet, train model from initial\n",
        "except:\n",
        "    print(\"Fail to load pretrained model...\")\n",
        "\n",
        "### Train your model\n",
        "model.fit((q_x, ans_x), ans_y, batch_size=BATCH_SIZE,epochs=EPOCHS,callbacks=[checkpoint, earlystop],verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCgJ1y6w1YHq",
        "outputId": "554eb0ac-3d9f-4b6c-b160-1b1189cd5b11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fail to load pre trained model...\n",
            "Epoch 1/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.4201 - accuracy: 0.6598\n",
            "Epoch 1: accuracy improved from -inf to 0.65981, saving model to ./models/chatbot_LSTM.h5\n",
            "774/774 [==============================] - 791s 1s/step - loss: 2.4201 - accuracy: 0.6598\n",
            "Epoch 2/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0652 - accuracy: 0.6811\n",
            "Epoch 2: accuracy improved from 0.65981 to 0.68107, saving model to ./models/chatbot_LSTM.h5\n",
            "774/774 [==============================] - 785s 1s/step - loss: 2.0652 - accuracy: 0.6811\n",
            "Epoch 3/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0609 - accuracy: 0.6810\n",
            "Epoch 3: accuracy did not improve from 0.68107\n",
            "774/774 [==============================] - 813s 1s/step - loss: 2.0609 - accuracy: 0.6810\n",
            "Epoch 4/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0592 - accuracy: 0.6811\n",
            "Epoch 4: accuracy improved from 0.68107 to 0.68114, saving model to ./models/chatbot_LSTM.h5\n",
            "774/774 [==============================] - 786s 1s/step - loss: 2.0592 - accuracy: 0.6811\n",
            "Epoch 5/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0579 - accuracy: 0.6811\n",
            "Epoch 5: accuracy did not improve from 0.68114\n",
            "774/774 [==============================] - 784s 1s/step - loss: 2.0579 - accuracy: 0.6811\n",
            "Epoch 6/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0572 - accuracy: 0.6810\n",
            "Epoch 6: accuracy did not improve from 0.68114\n",
            "774/774 [==============================] - 789s 1s/step - loss: 2.0572 - accuracy: 0.6810\n",
            "Epoch 7/10000\n",
            "774/774 [==============================] - ETA: 0s - loss: 2.0562 - accuracy: 0.6811\n",
            "Epoch 7: accuracy did not improve from 0.68114\n",
            "774/774 [==============================] - 782s 1s/step - loss: 2.0562 - accuracy: 0.6811\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f322cf1b640>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hdfBilcAs9l"
      },
      "source": [
        "model.save('chatbot.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmw1vMUBu1_l"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nIopkIqgBHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "f7e84a80-22a8-494d-db3a-bac58af8f32c"
      },
      "source": [
        "#跑下面inference前,要先改你要測試的model，否則就是前方訓練好的model\n",
        "#也可以不跑前方訓練，那就是這裡要記得import model\n",
        "model = model.load_model('chatbot.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-dc5c81e27700>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#跑下面inference前,要先改你要測試的model，否則就是前方訓練好的model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#也可以不跑前方訓練，那就是這裡要記得import model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chatbot.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'load_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSSstxDBu7Xc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8efc80fd-f734-4d74-803c-0a62ed19adde"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "Q_max_length = 42 #q_data max = 42, a_data max char = 70\n",
        "A_max_length = 70\n",
        "start = '<sos>'\n",
        "end = '<end>'\n",
        "token = Tokenizer(char_level=True,filters='',oov_token='<unk>')\n",
        "token.fit_on_texts(q)\n",
        "token.fit_on_texts(a)\n",
        "word_index = token.word_index\n",
        "index_word = token.index_word\n",
        "\n",
        "while True:\n",
        "  question = input('來點動漫話題: ')\n",
        "  if question == '滾': # 輸入 '滾' 即可結束Chat Bot\n",
        "    print('...88')\n",
        "    break\n",
        "  ans_seq = ''\n",
        "  cur_token = start\n",
        "  word_count = 1\n",
        "  target_seq = np.zeros((1,A_max_length),dtype='int64')\n",
        "  target_seq[0,0] = word_index[start]\n",
        "  q = fit_sentence(question,word_index,Q_max_length)\n",
        "  q = np.squeeze(q)\n",
        "  q = tf.expand_dims(q,0)\n",
        "  while word_count < A_max_length:\n",
        "    decoder_output = model.predict([q,target_seq])\n",
        "    ind = np.argmax(decoder_output[0,word_count])\n",
        "    cur_token = index_word[ind]\n",
        "    if cur_token == end:\n",
        "      break\n",
        "    ans_seq += cur_token\n",
        "    target_seq[0,word_count] = ind\n",
        "    word_count += 1\n",
        "  print(ans_seq)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "來點動漫話題: ya\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7e77b8b35dba>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '<sos>'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pethzqn5XoqR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
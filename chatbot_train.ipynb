{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mftkI0zPgMTo"
   },
   "source": [
    "# Requirement\n",
    "numpy==1.23.4\n",
    "\n",
    "pandas==1.5.3\n",
    "\n",
    "tensorflow==2.10.1\n",
    "\n",
    "tqdm==4.65.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OxhMDYz0aVy"
   },
   "source": [
    "# import library & parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AVuNvVDbgNyG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### Control tensorflow won't occupied all your GPU memory\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "### Configs --> Parameters you can attempt to tuning\n",
    "MAXLEN = 128 # If you data has short sentence, please try lower MAXLEN in order to increase performance of model training\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 64\n",
    "EMB_DIM = 100\n",
    "UNIT = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lLCGfzUKF4f"
   },
   "source": [
    "# load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQA4WATUztA4",
    "outputId": "0c78287e-7a82-4adf-bd8a-182ad2a47f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'C_Chat_Chatbot'...\n",
      "remote: Enumerating objects: 26, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 26 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (26/26), 6.21 MiB | 5.23 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/doudou030/C_Chat_Chatbot.git\n",
    "!cp C_Chat_Chatbot/train_data/train.txt train.txt\n",
    "!cp C_Chat_Chatbot/train_data/train.json train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT7H5nXJzrg_",
    "outputId": "8e2ba679-7fab-4ba8-ee43-46722bc921e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_data = []\n",
    "a_data = []\n",
    "f = open('/content/train.txt')\n",
    "lines = f.readlines() #總共行數\n",
    "for line in lines:\n",
    "    line = line.strip()  \n",
    "    if line.startswith('Q:'):\n",
    "        q_data.append(line[3:])  \n",
    "    elif line.startswith('A:'):\n",
    "        a_data.append(line[3:])  \n",
    "f.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ULVJIEKq0uBW"
   },
   "outputs": [],
   "source": [
    "q_data = np.array(q_data)\n",
    "a_data = np.array(a_data)\n",
    "q_data, a_data = shuffle(q_data,a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6XEsjnLrjTed"
   },
   "outputs": [],
   "source": [
    "q, a = [], []\n",
    "for i in range(len(q_data)):\n",
    "  seq_q, seq_a = q_data[i][0], a_data[i][0]\n",
    "  q.append(\"\".join(seq_q))\n",
    "  a.append(\"\".join(seq_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWp4HpRTkTyZ"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ijlnqTrDkTVT"
   },
   "outputs": [],
   "source": [
    "### Build character-based vocabulary\n",
    "def tokenize_chinese(texts, voc, voc_ind):\n",
    "    for t in tqdm(texts):\n",
    "        for ch in str(t):\n",
    "            if ch not in voc:\n",
    "                voc[ch] = voc_ind\n",
    "                voc_ind += 1 \n",
    "    return voc, voc_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TL8aadezMMC",
    "outputId": "82e49608-5c20-4622-c374-14ef86ba8b26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49478/49478 [00:00<00:00, 3242488.88it/s]\n",
      "100%|██████████| 49478/49478 [00:00<00:00, 2159881.91it/s]\n"
     ]
    }
   ],
   "source": [
    "voc = {} # Vocabulary dictionary\n",
    "voc_ind = 1 # vocabulary index start from 1, index 0 means nothing\n",
    "\n",
    "voc, voc_ind = tokenize_chinese(q, voc, voc_ind)\n",
    "voc, voc_ind = tokenize_chinese(a, voc, voc_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Daa4CTL82eWI"
   },
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8gNdd144kosm"
   },
   "outputs": [],
   "source": [
    "def fit_sentence(sen, voc):\n",
    "    res = []\n",
    "    for i in sen:\n",
    "        res.append(voc[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T5di4_qskXru"
   },
   "outputs": [],
   "source": [
    "### Insert \"Start Of Sentence\" token into vocabulary\n",
    "voc[\"<SOS>\"] = len(voc)+1\n",
    "### Insert \"End Of Sentence\" token into vocabulary\n",
    "voc[\"<EOS>\"] = len(voc)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LSfPi2jF0iEL"
   },
   "outputs": [],
   "source": [
    "q_x = []\n",
    "ans_x, ans_y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKWEkvAc0jF6",
    "outputId": "3025c183-9c54-4f08-8c6e-f0cf381941c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49478/49478 [00:01<00:00, 43921.10it/s]\n"
     ]
    }
   ],
   "source": [
    "### Question input\n",
    "for i in tqdm(q):\n",
    "    res = fit_sentence(i, voc)\n",
    "    while len(res) < MAXLEN: ### If sentence is shorter than maxlen, append 0 until length reach maxlen\n",
    "        res.append(0)\n",
    "    q_x.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I39Qkl-q0pja",
    "outputId": "d1edf0f6-a777-4ed6-d6fe-df52578254c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49478/49478 [00:01<00:00, 37537.20it/s]\n"
     ]
    }
   ],
   "source": [
    "### Answer input\n",
    "for i in tqdm(a):\n",
    "    res = fit_sentence(i, voc)\n",
    "    res.insert(0,voc[\"<SOS>\"])\n",
    "    res.append(voc[\"<EOS>\"])\n",
    "    while len(res) < MAXLEN: ### If sentence is shorter than maxlen, append 0 until length reach maxlen\n",
    "        res.append(0)\n",
    "    ans_x.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V6L5I8gw0uc1"
   },
   "outputs": [],
   "source": [
    "### Answer output\n",
    "for i in ans_x:\n",
    "    tmp = i[1:]\n",
    "    tmp.append(0)\n",
    "    ans_y.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p21tK9s50xsT"
   },
   "outputs": [],
   "source": [
    "### Turn into np.array for training\n",
    "q_x = np.array(q_x)\n",
    "ans_x = np.array(ans_x)\n",
    "ans_y = np.array(ans_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7Er55MSAl5T"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uJkAeP-eoF6f"
   },
   "outputs": [],
   "source": [
    "def build_model(voc):\n",
    "    Q_in = Input((MAXLEN,),name='Q_input')\n",
    "    Q_emb = Embedding(len(voc)+1,EMB_DIM,mask_zero=True,name='Q_emb')(Q_in)\n",
    "    Q_out, Q_h, Q_c = LSTM(UNIT,return_state=True,recurrent_dropout=0.2,name='Q_LSTM')(Q_emb)\n",
    "    Q_state = [Q_h,Q_c]\n",
    "    A_in = Input((MAXLEN,),name='A_input')\n",
    "    A_emb = Embedding(len(voc)+1,EMB_DIM,mask_zero=True,name='A_emb')(A_in)\n",
    "    A_out = LSTM(UNIT,return_sequences=True,recurrent_dropout=0.2,name='A_LSTM')(A_emb,initial_state=Q_state)\n",
    "    output = Dense(len(voc)+1,activation='softmax',name='Output')(A_out)\n",
    "\n",
    "    model = Model(inputs=[Q_in,A_in],outputs=output,name='Gossip_ChatBot')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ6HCEd7xKi1",
    "outputId": "cb6b56d0-ddee-4c69-fe47-cb1c2ce42419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Gossip_ChatBot\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Q_input (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " A_input (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " Q_emb (Embedding)              (None, 128, 100)     251100      ['Q_input[0][0]']                \n",
      "                                                                                                  \n",
      " A_emb (Embedding)              (None, 128, 100)     251100      ['A_input[0][0]']                \n",
      "                                                                                                  \n",
      " Q_LSTM (LSTM)                  [(None, 128),        117248      ['Q_emb[0][0]']                  \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " A_LSTM (LSTM)                  (None, 128, 128)     117248      ['A_emb[0][0]',                  \n",
      "                                                                  'Q_LSTM[0][1]',                 \n",
      "                                                                  'Q_LSTM[0][2]']                 \n",
      "                                                                                                  \n",
      " Output (Dense)                 (None, 128, 2511)    323919      ['A_LSTM[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,060,615\n",
      "Trainable params: 1,060,615\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(voc)\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCgJ1y6w1YHq",
    "outputId": "554eb0ac-3d9f-4b6c-b160-1b1189cd5b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to load pre trained model...\n",
      "Epoch 1/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.4201 - accuracy: 0.6598\n",
      "Epoch 1: accuracy improved from -inf to 0.65981, saving model to ./models/chatbot_LSTM.h5\n",
      "774/774 [==============================] - 791s 1s/step - loss: 2.4201 - accuracy: 0.6598\n",
      "Epoch 2/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0652 - accuracy: 0.6811\n",
      "Epoch 2: accuracy improved from 0.65981 to 0.68107, saving model to ./models/chatbot_LSTM.h5\n",
      "774/774 [==============================] - 785s 1s/step - loss: 2.0652 - accuracy: 0.6811\n",
      "Epoch 3/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0609 - accuracy: 0.6810\n",
      "Epoch 3: accuracy did not improve from 0.68107\n",
      "774/774 [==============================] - 813s 1s/step - loss: 2.0609 - accuracy: 0.6810\n",
      "Epoch 4/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0592 - accuracy: 0.6811\n",
      "Epoch 4: accuracy improved from 0.68107 to 0.68114, saving model to ./models/chatbot_LSTM.h5\n",
      "774/774 [==============================] - 786s 1s/step - loss: 2.0592 - accuracy: 0.6811\n",
      "Epoch 5/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0579 - accuracy: 0.6811\n",
      "Epoch 5: accuracy did not improve from 0.68114\n",
      "774/774 [==============================] - 784s 1s/step - loss: 2.0579 - accuracy: 0.6811\n",
      "Epoch 6/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0572 - accuracy: 0.6810\n",
      "Epoch 6: accuracy did not improve from 0.68114\n",
      "774/774 [==============================] - 789s 1s/step - loss: 2.0572 - accuracy: 0.6810\n",
      "Epoch 7/10000\n",
      "774/774 [==============================] - ETA: 0s - loss: 2.0562 - accuracy: 0.6811\n",
      "Epoch 7: accuracy did not improve from 0.68114\n",
      "774/774 [==============================] - 782s 1s/step - loss: 2.0562 - accuracy: 0.6811\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f322cf1b640>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Callbacks --> Checkpoint: Change file path to the directory where you want to save your model\n",
    "checkpoint = ModelCheckpoint(filepath=\"./models/chatbot_LSTM.h5\", monitor='accuracy',verbose=1,save_best_only=True,save_weights_only=True)\n",
    "### Callbacks --> Earlystop: Monitor accuracy and decide whether to stop the training procedure\n",
    "earlystop = EarlyStopping(monitor='accuracy',patience=3,verbose=1)\n",
    "\n",
    "### If you have model trained before, you can load it back and continue previous training procedure\n",
    "try:\n",
    "    model.load_weights('chatbot.h5')\n",
    "    print(\"Load model...\")\n",
    "### If you haven't train any model yet, train model from initial\n",
    "except:\n",
    "    print(\"Fail to load pretrained model...\")\n",
    "\n",
    "### Train your model\n",
    "model.fit((q_x, ans_x), ans_y, batch_size=BATCH_SIZE,epochs=EPOCHS,callbacks=[checkpoint, earlystop],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7hdfBilcAs9l"
   },
   "outputs": [],
   "source": [
    "model.save('chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pethzqn5XoqR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
